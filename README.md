```markdown
# ğŸ“¦ Inventory & Vendor Performance Analysis

An end-to-end analytics pipeline built for a growing manufacturing business managing diverse product lines. This personal portfolio project demonstrates industryâ€‘standard best practices in data ingestion, transformation, statistical analysis, and interactive dashboarding using anonymized transactional data.

> ğŸ“Œ This is a personal portfolio project intended for demonstration purposes only.

---

## ğŸ“– Overview

- **Domain:** Manufacturing company handling general products  
- **Data Scope:** Multiâ€‘millionâ€‘row CSV files for inventory, purchases, sales, and vendor invoices  
- **Objective:**  
  - Identify stock inefficiencies  
  - Reduce carrying costs  
  - Enhance vendor management  

---

## ğŸš€ Key Features

1. **ğŸ“¥ Data Ingestion & Audit Logging**  
   - `Ingestion/ingestion_db.py` loads raw CSV files into a SQL database  
   - Detailed logs captured in `Logs/ingestion_db.log` for full traceability  

2. **ğŸ”„ Data Transformation & Modeling**  
   - Combined SQL and Python workflows generate a clean, vendorâ€‘level summary table  

3. **ğŸ“Š Advanced Analytics & Statistical Testing**  
   - Jupyter notebooks perform EDA, feature engineering, and hypothesis testing on profit margins, stock turnover, and unsold inventory  

4. **ğŸ“ˆ Interactive Dashboarding**  
   - Power BI report visualizes KPIs such as profit margins, stockâ€‘toâ€‘sales ratios, and reorder recommendations  
   - Includes dynamic charts, tables, and KPI cards  

5. **ğŸ—‚ï¸ Modular, Scalable Structure**  
   - Clear separation of images, ingestion scripts, logs, and analysis notebooks  
   - Easy onboarding for new collaborators or future extensions  

---

## ğŸ“ Project Structure

```

Dashboard/
â”‚
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ Dashboard\_preview\.png        # Power BI dashboard snapshot
â”‚   â””â”€â”€ Vendor PerformanceDashboard.pbix  # Interactive Power BI file
â”‚
â”œâ”€â”€ Ingestion/
â”‚   â””â”€â”€ ingestion\_db.py              # Script for loading raw data into DB
â”‚
â”œâ”€â”€ Logs/
â”‚   â””â”€â”€ ingestion\_db.log             # ETL process logs
â”‚
â”œâ”€â”€ Notebooks/
â”‚   â”œâ”€â”€ Vendor Performance Analysis.ipynb        # Main EDA & insights
â”‚   â””â”€â”€ Vendor Performance Analysis (Transformed).ipynb  # Data Transormation & Summary table
â”‚
â”œâ”€â”€ .gitignore                       # Files/folders ignored by Git
â”œâ”€â”€ README.md                        # Project documentation (this file)
â””â”€â”€ requirements.txt                 # Python dependencies

````

---

## ğŸ› ï¸ Tech Stack & Dependencies

- **Python 3.x**: `pandas`, `numpy`, `SQLAlchemy`, `matplotlib`, `seaborn`, `scipy`, `statsmodels`  
- **SQL**: PostgreSQL or SQLite  
- **Jupyter Notebook**: Interactive data exploration  
- **Power BI**: Dashboard creation & reporting  
- **Logging**: Builtâ€‘in Python `logging` module  

Refer to `requirements.txt` for exact package versions.

---

## âš™ï¸ Setup & Installation

1. **Clone the repository**  
   ```bash
   git clone https://github.com/Saif907/vendor-performance-dashboard.git
   cd vendor-performance-dashboard
````

2. **Create & activate a virtual environment**

   ```bash
   python -m venv venv
   source venv/bin/activate      # macOS/Linux
   venv\Scripts\activate         # Windows
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

4. **Load raw data into the database**

   ```bash
   python Ingestion/ingestion_db.py
   ```

5. **Explore analysis notebooks**

   ```bash
   jupyter lab
   ```

   * `Vendor Performance Analysis.ipynb` â†’ EDA & insights
   * `Vendor Performance Analysis (Transformed).ipynb` â†’ Data Transformation & summary table

6. **View the Power BI dashboard**

   * Open Power BI Desktop and load
     `Dashboard/Vendor PerformanceDashboard.pbix`

---

## ğŸ“Š Dashboard Preview

![Dashboard Preview](images/Dashboard_preview.png)

---

## ğŸ™‹ Contact

**SaifÂ Shaikh**
ğŸ“§ saif81868@gmail.com
ğŸ”— www.linkedin.com/in/saif-shaikh-527346251

Feel free to explore the code and reach out with any questions or feedback!

```
```
